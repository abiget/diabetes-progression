---
title: "Exploring the Association Between Clinical Predictors and Diabetes Disease Progression: A Regression Analysis"
author: "Anteneh G. Yitayal 256983"
date: "2025-03-28"
output:
    pdf_document:
      latex_engine: xelatex
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(warning=FALSE,
message=FALSE,
tidy.opts=list(width.cutoff = 80),
tidy = FALSE)
```

```{r, include=FALSE}
library(pROC)
library(caret)
library(tidyverse)
library(class)
library(ggplot2)
library(dplyr)
if (!require(ROCR)) {
    install.packages(ROCR)
    library(ROCR)
}
library(tree)
library(randomForest)
```

## Introduction

Diabetes is a chronic metabolic disorder that poses significant health risks, including the progression of complications over time. Understanding the factors influencing disease progression is crucial for better patient management and prevention of severe outcomes. In this study, we investigate the relationship between disease progression after one year (measured as "progr") and various clinical predictors in a sample of 442 diabetic patients. The explanatory variables include age, sex, body mass index (BMI), average blood pressure (BP), total cholesterol (TC), low-density lipoproteins (LDL), high-density lipoproteins (HDL), the ratio between total cholesterol and HDL (TCH), triglyceride levels (TG), and blood glucose levels (GC). By analyzing these factors using regression techniques, the goal is to identify the key predictors of disease progression, thereby aiding in the development of more targeted treatment plans for diabetic patients.

## Objective

The objective of this analysis is to explore how different clinical factors like age, BMI, blood pressure, cholesterol levels, and blood glucose impact the progression of diabetes over one year. By using models like regression trees, random forests, and boosting it is aimed to identify which factors are most strongly related to the worsening of the disease. The goal is to find key predictors of diabetes progression and evaluate which model best explains the changes in disease over time, helping to improve patient care and treatment strategies.

## Data set

The dataset consists of 442 records with 11 features (10 predictors and 1 target variable). All variables are complete with no missing values. The target variable, disease progression ('progr'), shows considerable variation (25-346) with a mean of 152.1, suggesting diverse disease outcomes across patients. Key biomarkers show wide ranges: BMI (18.0-42.2), blood pressure (62-133 mmHg), and triglycerides (TG: 3.258-6.107). These ranges encompass both normal and significantly elevated values, providing a comprehensive dataset for modeling disease progression.

```{r, include=FALSE, echo=FALSE}
#load the data set and view data
data_df <- read.table("db.txt", header = TRUE)
data_size = dim(data_df)
#View(data_df)
sprintf("Records: %d Features: %d", data_size[1], data_size[2])
head(data_df)
```

```{r, include=FALSE, echo=FALSE}
#check missing values
check_missing_values <- function(data) {
  sprintf("#NaN values: %d", sum(is.na(data)))
  colSums(is.na(data))
}

check_missing_values(data_df)
```

```{r, echo=FALSE, include=FALSE}
str(data_df)
```

```{r, include=FALSE, echo=FALSE}
# convert categorical 'sex' into factor
data_df$sex <- as.factor(data_df$sex)

#check structure again
str(data_df)
```

```{r, include=FALSE, echo=FALSE}
summary(data_df)
```

```{r, include=FALSE, echo=FALSE}
#check structure and compute Pearson's r correlation
correlation <- cor(dplyr::select(data_df, -sex))
correlation
#Higher BMI seems to be associated with higher progr, BP, cholesterol, triglycerides, and glucose.Higher HDL (the "good" cholesterol) tends to have a protective (negative) relationship with these health issues and progr. LDL and TC are highly related, as expected for lipid profiles. progr is mainly linked to obesity-related measures (BMI, TG, BP, GC).
```

## Exploratory Data Analysis

The correlation heatmap in figure @ref(fig:fig1) reveals strong positive relationships between progr (disease progression) and both TG (triglycerides) and BMI, with moderately strong correlations with BP (blood pressure) and GC (glucose). HDL shows a notable negative correlation with progression, confirming its protective effect. The scatter plot in figure \@ref(fig:fig2) visually confirm these relationships, with clear positive trends between TG and disease progression, though with considerable variability this relationship is consistent for BP. The plot comparing disease progression by sex shows only minimal differences between males and females, with females showing slightly higher median values and marginally wider distribution, but this difference appears clinically insignificant compared to metabolic factors.

```{r fig1, echo=FALSE, fig.width=10, fig.height=4, fig.cap="Pairwise correlation among the variables and the target", fig.align="center"}
library(ggplot2)
library(reshape2)

corr_melt <- melt(correlation)
ggplot(corr_melt, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low="blue", mid="white", high="red", midpoint=0) +
  theme_minimal() +
  labs(title="Correlation Heatmap", x="", y="") +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14),
    axis.title = element_text(size = 12)
  )
```

```{r fig2, echo=FALSE, fig.width=10, fig.height=4, fig.cap="Distribution of Disease progression(Progr) with Triglycerides(TG)", fig.align="center"}

ggplot(data_df, aes(x = TG, y = progr)) +
  geom_point() +
  theme_minimal() +
  labs(title = "TG vs Progr", x = "TG", y = "Progr")+
  theme(
    plot.title = element_text(hjust = 0.5, size = 14),
    axis.title = element_text(size = 12)
  )
```

```{r fig3, echo=FALSE, fig.width=10, fig.height=4, fig.cap="\\label{fig:fig4} Distribution of Coronary Heart Disease(CHD) with Diastolic blood pressure.", fig.align="center"}
ggplot(data = data_df, aes(x = factor(sex, levels=c(1, 2), labels=c("Male", "Female")), y = progr)) +
  geom_boxplot(color = "black", fill="skyblue") +
  labs(title = "Progr vs Sex", x = "SEX", y = "Progr") +
  scale_fill_manual(values = c("skyblue", "lightpink")) + 
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14),
    axis.title = element_text(size = 12)
  )
```

## Methods

In this analysis, there are three main regression models used to predict disease progression: a decision tree, a random forest, and a boosting model. Each model is evaluated based on its predictive performance, interpretability, and the importance of the variables used.

### Decision Tree

```{r}
# Fit the decision tree model
set.seed(1) # for reproducibility
dec_tree_model <- tree(progr ~ ., data = data_df)
summary(dec_tree_model)
```

```{r, echo=FALSE, include=FALSE}
#par(mar = c(2, 2, 2, 2))
# increase height of the plot
# how to increase the plot height
# plot the unpruned tree
#par(mfrow = c(1, 1))
plot(dec_tree_model, col = "blue")
text(dec_tree_model, pretty = 1)
title("Disease Progression: Unpruned Tree")
```

The optimal tree size is computed using cross validation for the set of sizes, as in figure \@ref(fig:fig4) captures the essential bias-variance tradeoff in decision tree modeling, showing how predictive performance relates to model complexity. Starting with high deviance (poor performance) at tree size 1, the error rapidly decreases until reaching an optimal minimum at approximately 5 terminal nodes, after which the deviance gradually increases again as the tree grows to 12 nodes. This U-shaped curve clearly identifies the optimal spot where the model has sufficient complexity to capture important patterns in the data without overfitting to noise, validating the decision to prune the original 12-node tree down to approximately 5 nodes for optimal generalization performance. The graph serves as empirical evidence for selecting the appropriate level of model simplification, balancing predictive accuracy against interpretability and preventing overfitting.

```{r fig4, echo=FALSE, fig.width=10, fig.height=4, fig.cap="\\label{fig:fig4} Decision tree size for set of tree sizes", fig.align="center"}
set.seed(1)
cv_dec_tree_model <- cv.tree(dec_tree_model)
plot(cv_dec_tree_model$size , cv_dec_tree_model$dev , type = "b", 
     xlab = "Tree Size", ylab = "Deviance",
     main = "Decision Tree Deviance vs Tree Size")
```

The full regression tree (12 nodes) shows a 20% lower training error (residual mean deviance 2674) using five predictors (TG, BMI, HDL, GC, BP) compared to the pruned tree's simpler structure (5 nodes, deviance 3215) using only TG and BMI. While this indicates better data fitting by the full model, these metrics reflect performance on the same data used for training rather than generalization ability. The pruned model likely offers better future prediction performance despite its higher apparent error, as it reduces the risk of overfitting to noise in the training data, which clearly confirmed with cross validation as in Figure \@ref(fig:fig4).

```{r, include=TRUE, echo=TRUE}
set.seed(1)
# Prune the tree
pruned_tree <- prune.tree(dec_tree_model, best = 5)
summary(pruned_tree)
```

The pruned decision tree in figure \@ref(fig:fig5) provides a streamlined model for predicting diabetes progression using only triglycerides (TG) and BMI. It first splits patients based on TG levels at 4.60015, with lower values indicating better outcomes. Patients with low TG are further divided by BMI at 26.95, resulting in either mild progression (96.31) or moderate progression (159.70). Those with high TG branch according to BMI thresholds (27.75 and 32.75), revealing a clear severity gradient from moderate (162.70) to severe (208.60) to very severe progression (268.90). This elegant five-terminal node structure efficiently captures the essence that patients with both elevated triglycerides and high BMI face substantially worse disease outcomes, with each factor intensifying the other's impact.

```{r fig5, echo=FALSE, fig.width=10, fig.height=4, fig.cap="\\label{fig:fig4} Pruned Decision Tree diagram", fig.align="center"}
par(mar = c(5, 5, 5, 5))
plot(pruned_tree, col = "blue")
text(pruned_tree, pretty = 1)
title("Disease Progression: Pruned Tree")
```

### Random Forest

The random forest model was fitted to the data using 500 trees, with 10 variables randomly selected at each split. The mean squared residuals are 3384.245, which measures the average squared difference between observed and predicted values. The model explains about 42.86% of the variance in the response variable.

```{r, echo=TRUE, include=TRUE}
set.seed(1)
n_pred <- ncol(data_df) - 1
forest_tree_model <- randomForest(progr ~ ., data = data_df, mtry = n_pred, importance = TRUE)
forest_tree_model

```

```{r, echo=FALSE, include=FALSE}
# Plot the variable importance
varImpPlot(forest_tree_model, main = "Variable Importance Plot", col = "blue")
# Plot the error rate
plot(forest_tree_model, main = "Random Forest Error Rate", col = "blue")
legend("topright", legend = c("OOB Error Rate"), col = "blue", lty = 1)
```

The comparison between bagging model with all the features at each spiting and the random forst model reveals that the optimized model using only 2 variables per split (mtry=2) as shown in figure \@ref(fig:fig6), which was selected using ten-fold cross validation, outperforms the model using all 10 predictors (mtry=10), achieving a lower mean squared error (3244.603 vs 3384.245) and explaining more variance in diabetes progression (45.28% vs 42.93%). This about 4.2% improvement in error metrics demonstrates the effectiveness of the random variable selection process in creating more diverse trees while reducing the impact of overfitting. The result challenges the conventional wisdom of using more information at each decision point, confirming that carefully tuned hyperparameters can lead to more accurate predictions even when limiting the information available at each split. This finding emphasizes the importance of proper cross-validation for hyperparameter tuning in ensemble models rather than relying on default settings or using all available predictors.

```{r, echo=FALSE, include=TRUE}
library(randomForest)
library(caret)
set.seed(1)

# Define tuning grid
tuning_grid <- expand.grid(mtry = 1:n_pred)

# Train with cross-validation
rf_tune <- train(
  progr ~ .,
  data = data_df,
  method = "rf",
  tuneGrid = tuning_grid,
  trControl = trainControl(method = "cv", number = 10),
  importance = TRUE
)

```

```{r}
set.seed(1)
# Extract optimal mtry
optimal_mtry <- rf_tune$bestTune$mtry

# Fit the random forest model with optimal mtry
rf_model <- randomForest(progr ~ ., data = data_df, mtry = optimal_mtry, ntree = 500)
# Print the model summary
print(rf_model)
```

```{r fig6, echo=FALSE, fig.width=10, fig.height=4, fig.cap="\\label{fig:fig4} Random Forest RMSE with different number of randomly selected featues", fig.align="center"}

# View results
#print(rf_tune)
plot(rf_tune, main='Cross validation RMSE Vs Randomly selected number of featues at each split')  # Creates the RMSE vs mtry plot

```

This plot in figure \@ref(fig:fig7) shows the relative importance of different predictors in explaining diabetes progression. Triglycerides (TG) and Body Mass Index (BMI) emerge as the most influential factors by a substantial margin, with TG slightly outperforming BMI. Blood pressure (BP) ranks as the third most important predictor, followed by HDL cholesterol and glucose control (GC) with moderate importance.

```{r fig7, echo=FALSE, fig.width=10, fig.height=4, fig.cap="\\label{fig:fig4} Random Feature importance", fig.align="center"}
# Plot the variable importance
varImpPlot(rf_model, main = "Feature Importance", col = "blue")
# Plot the error rate
#plot(rf_model, main = "Random Forest Error Rate", col = "blue")
#legend("topright", legend = c("OOB Error Rate"), col = "blue", lty = 1)
# Predict on the same data to calculate RMSE (for training data)
predictions <- predict(rf_model, data_df)
# Calculate RMSE (Root Mean Squared Error)
rmse <- sqrt(mean((predictions - data_df$progr)^2))
```

### Boosting

A gradient boosted model with gaussian loss function model was fitted with 5000 trees, a shrinkage of 0.01 which is common, and a maximum interaction depth of 4. The optimal number of trees is selected using ten-fold cross validation for a series of number of tree of multiple of 100 between 100 and 2000 and the the minimum observations at the termial node set to 10 while keeping the other parameters the same, the RMSE is the lowest at the number of tress of 400 as shown in figure 8.

The optimized model with 400 trees reveals that diabetes progression is predominantly driven by just two metabolic factors (BMI and triglycerides), with a significant secondary contribution from blood pressure. The concentration of predictive power in these variables suggests that interventions targeting weight management and lipid control would likely have the greatest impact on diabetes outcomes.

```{r, echo=FALSE, include=FALSE}
library(gbm)
set.seed(1)

boosted <- gbm(progr ~ ., data = data_df, distribution = "gaussian", n.trees = 5000, interaction.depth = 4, shrinkage = 0.01, verbose = FALSE)

summary(boosted)
#boosted
```

```{r, echo=FALSE, include=FALSE}
set.seed(1)
# 1. Use cross-validation to find optimal parameters
# Create training control with 10-fold CV
ctrl <- trainControl(
  method = "cv", 
  number = 10,
  verboseIter = FALSE
)

# Create parameter grid for tuning
# Focus on n.trees while using reasonable defaults for other parameters
gbm_grid <- expand.grid(
  n.trees = seq(100, 2000, by = 100),      # Number of trees/iterations
  interaction.depth = 4,                   # Moderate tree depth
  shrinkage = 0.01,                        # Conservative learning rate
  n.minobsinnode = 10                      # Minimum observations in terminal nodes
)

# Fit GBM model with cross-validation
gbm_tuned <- train(
  progr ~ .,
  data = data_df,
  method = "gbm",
  distribution = "gaussian",
  trControl = ctrl,
  tuneGrid = gbm_grid,
  verbose = FALSE
)
```

```{r fig8, echo=FALSE, fig.width=10, fig.height=4, fig.cap="\\label{fig:fig4} Gradient Boosting Performance by Number of Trees", fig.align="center"}
# Print tuning results and best parameters
tunned_results <- gbm_tuned$results


ggplot(tunned_results, aes(x = n.trees, y = RMSE)) +
  geom_line(color = "steelblue", size = 1) +
  geom_point(size = 2, color = "steelblue") +
  geom_vline(xintercept = gbm_tuned$bestTune$n.trees, 
             color = "red", linetype = "dashed", size = 1) +
  geom_point(data = tunned_results[which.min(tunned_results$RMSE), ], 
             aes(x = n.trees, y = RMSE), 
             color = "red", size = 4) +
  annotate("text", 
           x = gbm_tuned$bestTune$n.trees + max(tunned_results$n.trees)/20, 
           y = min(tunned_results$RMSE) + 0.2, 
           label = paste("Optimal trees:", gbm_tuned$bestTune$n.trees), 
           hjust = 0) +
  labs(title = "Gradient Boosting Performance vs Number of Trees",
       subtitle = paste("Optimal model uses", gbm_tuned$bestTune$n.trees, "trees with minimum RMSE of", 
                        round(min(tunned_results$RMSE), 2)),
       x = "Number of Trees",
       y = "RMSE (Cross-Validated)") +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 14),
    plot.subtitle = element_text(size = 11, hjust=0.5, color = "darkgrey"),
    axis.title = element_text(face = "bold"),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "gray90")
  )
```

The feature importance distribution in figure 9 reveals that just two metabolic factors (TG and BMI) account for over 66% of the predictive power, while the top three factors (including BP) represent more than 77% of the model's predictive capability. This strongly supports focusing clinical interventions on triglycerides, BMI, and blood pressure for managing diabetes progression.

```{r, include=FALSE, echo=FALSE}
set.seed(1)
# 2. Fit final model with optimal number of trees
optimal_trees <- gbm_tuned$bestTune$n.trees

final_gbm <- gbm(
  progr ~ .,
  data = data_df,
  distribution = "gaussian",
  n.trees = optimal_trees,
  interaction.depth = 3,
  shrinkage = 0.01,
  n.minobsinnode = 10,
  cv.folds = 10,                # Include CV for validation
  verbose = FALSE
)
```

```{r figx, eval=FALSE, fig.align="center", fig.cap="\\label{fig:fig4} Gradient Boosting ", fig.height=4, fig.width=10, include=FALSE}
# 3. Model diagnostics and interpretation
# Plot training error vs number of trees
plot(final_gbm$train.error, type = "l", 
     xlab = "Number of Trees", ylab = "Training Error",
     main = "Training Error vs Boosting Iterations")
abline(v = optimal_trees, col = "red", lty = 2)

```

```{r fig9, echo=FALSE, fig.align="center", fig.cap="\\label{fig:fig4} Gradient Boosting relative feature importance", fig.height=4, fig.width=10, include=TRUE}
# Plot variable importance
# Method 1: Extract the importance data manually and plot with ggplot2
imp_data <- summary(final_gbm, plotit = FALSE)
imp_df <- data.frame(Variable = imp_data$var, 
                     Importance = imp_data$rel.inf)

# Create plot with all variables properly labeled
library(ggplot2)
ggplot(imp_df, aes(x = Importance, y = reorder(Variable, Importance))) +
  geom_bar(stat = "identity", fill = "blue") +
  labs(title = "Variable Importance in GBM Model",
       x = "Relative influence (%)",
       y = "") +
  theme_minimal() +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 14),
    axis.title = element_text(face = "bold"),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "gray90")
  )
```

### Results and Discussion

A comprehensive 10-fold cross-validation framework was used to compare the three statistical models. For each fold, the data is split into training and testing sets, then each model is optimized and evaluated:

1.  **Decision Trees**: First builds a full tree, then uses cross validation to determine the optimal complexity parameter, prunes accordingly, and calculates RMSE on the test fold.

2.  **Random Forests**: Evaluates 10 different mtry values (variables considered at each split) using OOB error to select the optimal value, then builds a forest with 500 trees and this optimal mtry parameter.

3.  **Gradient Boosting**: Uses 10-fold cross-validation to identify the best combination of hyperparameters from a grid of options: number of trees (100, 400, 500, 1000), interaction depth (1, 4, 5), and shrinkage (0.01, 0.1).

After collecting RMSE values for all 10 folds, the mean performance and standard deviations for each method was calculated, providing a robust comparison of predictive accuracy across the models. The boxplot in figure 10 compares the cross-validated performance of the models show that Random Forest demonstrates the best overall performance with the lowest median RMSE and narrowest distribution, indicating consistent predictive ability across different data subsets. Gradient Boosting shows competitive performance with slightly higher variability but maintains strong predictive power. Decision Trees exhibit the highest median RMSE and widest spread, confirming they are the least accurate and most variable of the three approaches. The Random Forest's superior performance likely stems from its ability to capture complex relationships between key metabolic factors (TG, BMI, BP) while reducing overfitting through ensemble averaging.

```{r, echo=FALSE, include=FALSE}
# Set seed for reproducibility
set.seed(1)

# Create 10-fold cross-validation indices
folds <- createFolds(data_df$progr, k = 10)

# Storage for results
results <- data.frame(
  Fold = 1:10,
  DecisionTree_RMSE = NA,
  RandomForest_RMSE = NA,
  Boosting_RMSE = NA
)

# Perform cross-validation
for (i in 1:10) {
  # Prepare training and test data
  test_indices <- folds[[i]]
  train_data <- data_df[-test_indices, ]
  test_data <- data_df[test_indices, ]
  
  # 1. Cost-complexity pruned decision tree
  # First grow a full tree
  full_tree <- tree(progr ~ ., data = train_data)
  # Cross-validate to find optimal complexity
  cv_tree <- cv.tree(full_tree)
  optimal_size <- cv_tree$size[which.min(cv_tree$dev)]
  # Prune tree to optimal size
  pruned_tree <- prune.tree(full_tree, best = optimal_size)
  # Predict and calculate RMSE
  dt_pred <- predict(pruned_tree, test_data)
  results$DecisionTree_RMSE[i] <- sqrt(mean((dt_pred - test_data$progr)^2))
  
  # 2. Random Forest with optimized mtry
  # Use OOB error to select mtry
  mtry_values <- 1:10
  oob_errors <- numeric(length(mtry_values))
  for (m in mtry_values) {
    rf_temp <- randomForest(progr ~ ., data = train_data, mtry = m, ntree = 500)
    oob_errors[m] <- tail(rf_temp$mse, 1)
  }
  optimal_mtry <- which.min(oob_errors)
  # Train final RF model with optimal mtry
  rf_model <- randomForest(progr ~ ., data = train_data, mtry = optimal_mtry, ntree = 500)
  # Predict and calculate RMSE
  rf_pred <- predict(rf_model, test_data)
  results$RandomForest_RMSE[i] <- sqrt(mean((rf_pred - test_data$progr)^2))
  
  # 3. Boosting (GBM) with optimized parameters
  # Cross-validate to find optimal parameters
  gbm_grid <- expand.grid(
    n.trees = c(100, 400, 500, 1000),
    interaction.depth = c(1, 4, 5),
    shrinkage = c(0.01, 0.1),
    n.minobsinnode = 10
  )
  gbm_cv <- train(
    progr ~ .,
    data = train_data,
    method = "gbm",
    tuneGrid = gbm_grid,
    trControl = trainControl(method = "cv", number = 10),
    verbose = FALSE
  )
  # Train final boosting model with optimal parameters
  boost_model <- gbm(
    progr ~ .,
    data = train_data,
    distribution = "gaussian",
    n.trees = gbm_cv$bestTune$n.trees,
    interaction.depth = gbm_cv$bestTune$interaction.depth,
    shrinkage = gbm_cv$bestTune$shrinkage,
    n.minobsinnode = gbm_cv$bestTune$n.minobsinnode,
    verbose = FALSE
  )
  # Predict and calculate RMSE
  boost_pred <- predict(boost_model, test_data, n.trees = gbm_cv$bestTune$n.trees)
  results$Boosting_RMSE[i] <- sqrt(mean((boost_pred - test_data$progr)^2))
}
```

```{r, echo=FALSE, include=FALSE}
# Summarize results
mean_results <- colMeans(results[, -1])
sd_results <- apply(results[, -1], 2, sd)
final_comparison <- data.frame(
  Model = c("Decision Tree", "Random Forest", "Boosting"),
  Mean_RMSE = mean_results,
  SD_RMSE = sd_results
)

# Print and visualize results
print(final_comparison)
```

```{r fig10, echo=FALSE, fig.align="center", fig.cap="\\label{fig:fig4} Performance comparision among the models", fig.height=4, fig.width=10, include=TRUE}
boxplot(results[, -1], main="Model Performance Comparison", 
        ylab="RMSE (lower is better)", col=c("lightblue","lightgreen","salmon"))
```

### Conclusion

This analysis demonstrates that ensemble methods provide superior predictive performance for diabetes progression while maintaining valuable clinical interpretability. The findings support focusing clinical attention on metabolic factors, particularly triglycerides and BMI, when developing interventions to slow disease progression. Future work could explore additional biomarkers, temporal dynamics of progression, and patient-specific response patterns.

### References

1.  Gareth James, Daniela Witten, Trevor Hastie, Robert Tibshirani. An Introduction to Statistical Learning : with Applications in R. New York :Springer, 2013.

*Source code: https://github.com/abiget/*diabetes-progression
